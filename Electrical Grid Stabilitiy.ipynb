{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8675</th>\n",
       "      <td>8.890486</td>\n",
       "      <td>5.645561</td>\n",
       "      <td>3.155660</td>\n",
       "      <td>0.642751</td>\n",
       "      <td>2.427443</td>\n",
       "      <td>-0.629514</td>\n",
       "      <td>-0.942476</td>\n",
       "      <td>-0.855453</td>\n",
       "      <td>0.973431</td>\n",
       "      <td>0.889785</td>\n",
       "      <td>0.057963</td>\n",
       "      <td>0.504504</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>0.509928</td>\n",
       "      <td>1.790421</td>\n",
       "      <td>6.331719</td>\n",
       "      <td>1.518084</td>\n",
       "      <td>5.052228</td>\n",
       "      <td>-1.683956</td>\n",
       "      <td>-1.700754</td>\n",
       "      <td>-1.667518</td>\n",
       "      <td>0.799044</td>\n",
       "      <td>0.062329</td>\n",
       "      <td>0.628171</td>\n",
       "      <td>0.898306</td>\n",
       "      <td>-0.045465</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>5.116781</td>\n",
       "      <td>1.349771</td>\n",
       "      <td>7.083652</td>\n",
       "      <td>0.856951</td>\n",
       "      <td>4.007726</td>\n",
       "      <td>-1.651605</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-0.918095</td>\n",
       "      <td>0.525354</td>\n",
       "      <td>0.517443</td>\n",
       "      <td>0.265501</td>\n",
       "      <td>0.720542</td>\n",
       "      <td>-0.050075</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4.985250</td>\n",
       "      <td>5.316307</td>\n",
       "      <td>2.623230</td>\n",
       "      <td>6.907926</td>\n",
       "      <td>3.540059</td>\n",
       "      <td>-0.542270</td>\n",
       "      <td>-1.849743</td>\n",
       "      <td>-1.148045</td>\n",
       "      <td>0.955232</td>\n",
       "      <td>0.161374</td>\n",
       "      <td>0.318092</td>\n",
       "      <td>0.953997</td>\n",
       "      <td>0.060267</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8080</th>\n",
       "      <td>5.791831</td>\n",
       "      <td>8.807734</td>\n",
       "      <td>3.001974</td>\n",
       "      <td>8.224824</td>\n",
       "      <td>3.705504</td>\n",
       "      <td>-1.336670</td>\n",
       "      <td>-1.750091</td>\n",
       "      <td>-0.618743</td>\n",
       "      <td>0.166102</td>\n",
       "      <td>0.818971</td>\n",
       "      <td>0.168872</td>\n",
       "      <td>0.078901</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "8675  8.890486  5.645561  3.155660  0.642751  2.427443 -0.629514 -0.942476   \n",
       "4226  0.509928  1.790421  6.331719  1.518084  5.052228 -1.683956 -1.700754   \n",
       "4335  5.116781  1.349771  7.083652  0.856951  4.007726 -1.651605 -1.438026   \n",
       "58    4.985250  5.316307  2.623230  6.907926  3.540059 -0.542270 -1.849743   \n",
       "8080  5.791831  8.807734  3.001974  8.224824  3.705504 -1.336670 -1.750091   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab     stabf  \n",
       "8675 -0.855453  0.973431  0.889785  0.057963  0.504504  0.027116  unstable  \n",
       "4226 -1.667518  0.799044  0.062329  0.628171  0.898306 -0.045465    stable  \n",
       "4335 -0.918095  0.525354  0.517443  0.265501  0.720542 -0.050075    stable  \n",
       "58   -1.148045  0.955232  0.161374  0.318092  0.953997  0.060267  unstable  \n",
       "8080 -0.618743  0.166102  0.818971  0.168872  0.078901  0.006705  unstable  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(r\"C:\\Datasets\\Grid_Stability.csv\")\n",
    "df.sample(5)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stabf']=df['stabf'].replace(['unstable','stable'],['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9675</th>\n",
       "      <td>0.508533</td>\n",
       "      <td>7.505413</td>\n",
       "      <td>9.537115</td>\n",
       "      <td>6.335474</td>\n",
       "      <td>3.841209</td>\n",
       "      <td>-0.751184</td>\n",
       "      <td>-1.688099</td>\n",
       "      <td>-1.401927</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.967824</td>\n",
       "      <td>0.184285</td>\n",
       "      <td>0.342387</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>5.671346</td>\n",
       "      <td>2.910891</td>\n",
       "      <td>0.933075</td>\n",
       "      <td>5.402689</td>\n",
       "      <td>4.033685</td>\n",
       "      <td>-1.764620</td>\n",
       "      <td>-1.571622</td>\n",
       "      <td>-0.697443</td>\n",
       "      <td>0.218617</td>\n",
       "      <td>0.072572</td>\n",
       "      <td>0.329413</td>\n",
       "      <td>0.702260</td>\n",
       "      <td>-0.038307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4714</th>\n",
       "      <td>7.625085</td>\n",
       "      <td>7.447413</td>\n",
       "      <td>9.449057</td>\n",
       "      <td>1.837484</td>\n",
       "      <td>4.319625</td>\n",
       "      <td>-0.839069</td>\n",
       "      <td>-1.494933</td>\n",
       "      <td>-1.985623</td>\n",
       "      <td>0.782642</td>\n",
       "      <td>0.351340</td>\n",
       "      <td>0.764087</td>\n",
       "      <td>0.692477</td>\n",
       "      <td>0.044578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>3.783991</td>\n",
       "      <td>2.123360</td>\n",
       "      <td>0.561618</td>\n",
       "      <td>6.481342</td>\n",
       "      <td>4.216664</td>\n",
       "      <td>-1.120745</td>\n",
       "      <td>-1.119174</td>\n",
       "      <td>-1.976745</td>\n",
       "      <td>0.295335</td>\n",
       "      <td>0.384226</td>\n",
       "      <td>0.535711</td>\n",
       "      <td>0.760425</td>\n",
       "      <td>-0.022789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>8.866032</td>\n",
       "      <td>5.425236</td>\n",
       "      <td>6.565836</td>\n",
       "      <td>2.660482</td>\n",
       "      <td>3.310254</td>\n",
       "      <td>-1.126282</td>\n",
       "      <td>-1.119518</td>\n",
       "      <td>-1.064455</td>\n",
       "      <td>0.688851</td>\n",
       "      <td>0.563890</td>\n",
       "      <td>0.910219</td>\n",
       "      <td>0.627341</td>\n",
       "      <td>0.064781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "9675  0.508533  7.505413  9.537115  6.335474  3.841209 -0.751184 -1.688099   \n",
       "3268  5.671346  2.910891  0.933075  5.402689  4.033685 -1.764620 -1.571622   \n",
       "4714  7.625085  7.447413  9.449057  1.837484  4.319625 -0.839069 -1.494933   \n",
       "1802  3.783991  2.123360  0.561618  6.481342  4.216664 -1.120745 -1.119174   \n",
       "9729  8.866032  5.425236  6.565836  2.660482  3.310254 -1.126282 -1.119518   \n",
       "\n",
       "            p4        g1        g2        g3        g4      stab stabf  \n",
       "9675 -1.401927  0.157118  0.967824  0.184285  0.342387  0.025070     0  \n",
       "3268 -0.697443  0.218617  0.072572  0.329413  0.702260 -0.038307     1  \n",
       "4714 -1.985623  0.782642  0.351340  0.764087  0.692477  0.044578     0  \n",
       "1802 -1.976745  0.295335  0.384226  0.535711  0.760425 -0.022789     1  \n",
       "9729 -1.064455  0.688851  0.563890  0.910219  0.627341  0.064781     0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.250000</td>\n",
       "      <td>5.250001</td>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249997</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.015731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.742548</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742549</td>\n",
       "      <td>2.742556</td>\n",
       "      <td>0.752160</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.274256</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.274255</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.500793</td>\n",
       "      <td>0.500141</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.500473</td>\n",
       "      <td>1.582590</td>\n",
       "      <td>-1.999891</td>\n",
       "      <td>-1.999945</td>\n",
       "      <td>-1.999926</td>\n",
       "      <td>0.050009</td>\n",
       "      <td>0.050053</td>\n",
       "      <td>0.050054</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.080760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.874892</td>\n",
       "      <td>2.875140</td>\n",
       "      <td>2.875522</td>\n",
       "      <td>2.874950</td>\n",
       "      <td>3.218300</td>\n",
       "      <td>-1.624901</td>\n",
       "      <td>-1.625025</td>\n",
       "      <td>-1.624960</td>\n",
       "      <td>0.287521</td>\n",
       "      <td>0.287552</td>\n",
       "      <td>0.287514</td>\n",
       "      <td>0.287494</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.250004</td>\n",
       "      <td>5.249981</td>\n",
       "      <td>5.249979</td>\n",
       "      <td>5.249734</td>\n",
       "      <td>3.751025</td>\n",
       "      <td>-1.249966</td>\n",
       "      <td>-1.249974</td>\n",
       "      <td>-1.250007</td>\n",
       "      <td>0.525009</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.525015</td>\n",
       "      <td>0.525002</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.624690</td>\n",
       "      <td>7.624893</td>\n",
       "      <td>7.624948</td>\n",
       "      <td>7.624838</td>\n",
       "      <td>4.282420</td>\n",
       "      <td>-0.874977</td>\n",
       "      <td>-0.875043</td>\n",
       "      <td>-0.875065</td>\n",
       "      <td>0.762435</td>\n",
       "      <td>0.762490</td>\n",
       "      <td>0.762440</td>\n",
       "      <td>0.762433</td>\n",
       "      <td>0.044878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999469</td>\n",
       "      <td>9.999837</td>\n",
       "      <td>9.999450</td>\n",
       "      <td>9.999443</td>\n",
       "      <td>5.864418</td>\n",
       "      <td>-0.500108</td>\n",
       "      <td>-0.500072</td>\n",
       "      <td>-0.500025</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.109403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tau1          tau2          tau3          tau4            p1  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       5.250000      5.250001      5.250004      5.249997      3.750000   \n",
       "std        2.742548      2.742549      2.742549      2.742556      0.752160   \n",
       "min        0.500793      0.500141      0.500788      0.500473      1.582590   \n",
       "25%        2.874892      2.875140      2.875522      2.874950      3.218300   \n",
       "50%        5.250004      5.249981      5.249979      5.249734      3.751025   \n",
       "75%        7.624690      7.624893      7.624948      7.624838      4.282420   \n",
       "max        9.999469      9.999837      9.999450      9.999443      5.864418   \n",
       "\n",
       "                 p2            p3            p4            g1            g2  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -1.250000     -1.250000     -1.250000      0.525000      0.525000   \n",
       "std        0.433035      0.433035      0.433035      0.274256      0.274255   \n",
       "min       -1.999891     -1.999945     -1.999926      0.050009      0.050053   \n",
       "25%       -1.624901     -1.625025     -1.624960      0.287521      0.287552   \n",
       "50%       -1.249966     -1.249974     -1.250007      0.525009      0.525003   \n",
       "75%       -0.874977     -0.875043     -0.875065      0.762435      0.762490   \n",
       "max       -0.500108     -0.500072     -0.500025      0.999937      0.999944   \n",
       "\n",
       "                 g3            g4          stab  \n",
       "count  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.525000      0.525000      0.015731  \n",
       "std        0.274255      0.274255      0.036919  \n",
       "min        0.050054      0.050028     -0.080760  \n",
       "25%        0.287514      0.287494     -0.015557  \n",
       "50%        0.525015      0.525002      0.017142  \n",
       "75%        0.762440      0.762433      0.044878  \n",
       "max        0.999982      0.999930      0.109403  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To view some basic Statistical Details\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     float64\n",
       "tau2     float64\n",
       "tau3     float64\n",
       "tau4     float64\n",
       "p1       float64\n",
       "p2       float64\n",
       "p3       float64\n",
       "p4       float64\n",
       "g1       float64\n",
       "g2       float64\n",
       "g3       float64\n",
       "g4       float64\n",
       "stab     float64\n",
       "stabf     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1     0\n",
       "tau2     0\n",
       "tau3     0\n",
       "tau4     0\n",
       "p1       0\n",
       "p2       0\n",
       "p3       0\n",
       "p4       0\n",
       "g1       0\n",
       "g2       0\n",
       "g3       0\n",
       "g4       0\n",
       "stab     0\n",
       "stabf    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(corr, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tau1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau3</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau4</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p2</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p3</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p4</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g3</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tau1  tau2  tau3  tau4    p1    p2    p3    p4    g1    g2    g3    g4  \\\n",
       "tau1  1.00  0.02 -0.01 -0.02  0.03 -0.02 -0.02 -0.02  0.01  0.02 -0.00  0.01   \n",
       "tau2  0.02  1.00  0.01 -0.00 -0.00  0.01  0.01 -0.01 -0.00  0.02  0.02 -0.01   \n",
       "tau3 -0.01  0.01  1.00  0.00  0.02 -0.00 -0.01 -0.02 -0.01  0.01  0.01 -0.01   \n",
       "tau4 -0.02 -0.00  0.00  1.00 -0.00  0.01  0.01 -0.01 -0.00  0.01  0.00 -0.00   \n",
       "p1    0.03 -0.00  0.02 -0.00  1.00 -0.57 -0.58 -0.58  0.00  0.02  0.00 -0.02   \n",
       "p2   -0.02  0.01 -0.00  0.01 -0.57  1.00  0.00 -0.01  0.02 -0.02  0.01  0.02   \n",
       "p3   -0.02  0.01 -0.01  0.01 -0.58  0.00  1.00  0.01 -0.00 -0.01 -0.01 -0.01   \n",
       "p4   -0.02 -0.01 -0.02 -0.01 -0.58 -0.01  0.01  1.00 -0.01  0.00 -0.00  0.02   \n",
       "g1    0.01 -0.00 -0.01 -0.00  0.00  0.02 -0.00 -0.01  1.00  0.01 -0.01  0.01   \n",
       "g2    0.02  0.02  0.01  0.01  0.02 -0.02 -0.01  0.00  0.01  1.00 -0.01 -0.01   \n",
       "g3   -0.00  0.02  0.01  0.00  0.00  0.01 -0.01 -0.00 -0.01 -0.01  1.00  0.01   \n",
       "g4    0.01 -0.01 -0.01 -0.00 -0.02  0.02 -0.01  0.02  0.01 -0.01  0.01  1.00   \n",
       "stab  0.28  0.29  0.28  0.28  0.01  0.01 -0.00 -0.02  0.28  0.29  0.31  0.28   \n",
       "\n",
       "      stab  \n",
       "tau1  0.28  \n",
       "tau2  0.29  \n",
       "tau3  0.28  \n",
       "tau4  0.28  \n",
       "p1    0.01  \n",
       "p2    0.01  \n",
       "p3   -0.00  \n",
       "p4   -0.02  \n",
       "g1    0.28  \n",
       "g2    0.29  \n",
       "g3    0.31  \n",
       "g4    0.28  \n",
       "stab  1.00  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df.corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d6d33b6220>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df['stab'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEGCAYAAABbzE8LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMB0lEQVR4nO3df4zkd13H8debOyktUrAWKhzotR5KMBophWC0JoRG26r4K0H4B6J/EIxerjEYMU0U/zCmIsZ6MZAaDagIxijRaEmqhGhi+HX9XdIC21oiRykt1bbxahH4+Md8l4zL3u3c7s6897jHI9ns3Hx/vec7e8/OzHbmaowRAFbvKd0DAJytBBigiQADNBFggCYCDNBk/+msfOGFF46DBw8uaRSAb0w333zzw2OMZ2+8/rQCfPDgwRw7dmz3pgI4C1TVZza73ksQAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNDmtfxOOb0xHjx7N2tpa9xi76vjx40mSAwcONE+yuEOHDuXw4cPdY7BCAkzW1tZy21135yvnXdA9yq7Zd+LRJMnnnzwzfsT3nXikewQanBk/nSzdV867IE+86OruMXbNuffcmCRnzG1an5ezi9eAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGarCTAR48ezdGjR1dxKIBdtcx+7V/KXjdYW1tbxWEAdt0y++UlCIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJvtXcZDjx4/niSeeyJEjR1ZxOE7T2tpanvKl0T3GWe0p//NY1tYe93dkD1pbW8u55567lH1v+Qi4qt5YVceq6thDDz20lCEAzkZbPgIeY9yQ5IYkueyyy7b1MOnAgQNJkuuvv347m7NkR44cyc33Pdg9xlntq087P4cuucjfkT1omc9KvAYM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGa7F/FQQ4dOrSKwwDsumX2ayUBPnz48CoOA7DrltkvL0EANBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoIkAAzQRYIAmAgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoIsAATQQYoMn+7gHYG/adeCTn3nNj9xi7Zt+JLybJGXOb9p14JMlF3WOwYgJMDh061D3Crjt+/MtJkgMHzpSoXfQNeT9wagJMDh8+3D0CnJW8BgzQRIABmggwQBMBBmgiwABNBBigiQADNBFggCYCDNBEgAGaCDBAEwEGaCLAAE0EGKCJAAM0EWCAJgIM0ESAAZoIMEATAQZoUmOMxVeueijJZ5Y3Ti5M8vAS979T5tsZ8+2M+Xamc77vGGM8e+OVpxXgZauqY2OMy7rnOBnz7Yz5dsZ8O7MX5/MSBEATAQZostcCfEP3AFsw386Yb2fMtzN7br499RowwNlkrz0CBjhrCDBAk5UEuKouqKp/qqpPT9+/5STrXVlVn6yqtap6y9z1f1VVt01f91fVbdP1B6vqibll72ya761VdXxujqvnlv36tP4nq+pHm+Z7W1XdU1V3VNX7q+pZ0/XbPn8nO9bc8qqqP5yW31FVly4w50K3c5nzVdULqupDVXV3VX2iqo7MbXPS+3lV803L7q+qO6cZjs1dvxfO33fPnZ/bquqxqrpmWrbK8/eiqvpwVT1ZVW9eZNvdPH8LG2Ms/SvJ7yZ5y3T5LUmu22SdfUnuTXJJkqcmuT3JizdZ7+1JfmO6fDDJXd3zJXlrkjdvss2Lp/XOSXLxtP2+hvl+JMn+6fJ169tv9/wtcl8luTrJB5JUklck+egCc255O1cw33OTXDpdfkaST211P69yvmnZ/Uku3M7PySrm27Cfz2f2JoRVn7/nJHlZkt+eP+Yqfv5O52tVL0H8ZJJ3T5ffneSnNlnn5UnWxhj3jTG+lOR903ZfU1WV5DVJ3rsX5zvJft83xnhyjPHvSdam/ax0vjHGTWOML0/rfSTJ87cxw0LH2jDzn42ZjyR5VlU9d4ttF7mdS51vjPHAGOOWJBljPJ7k7iQHtjnHrs+3xX7bz9+GdV6V5N4xxm6/e3bL+cYYXxhjfDzJ/57Gtrt1/ha2qgBfNMZ4IEmm78/ZZJ0DSf5j7s+fzdf/4F+e5MExxqfnrru4qm6tqn+pqssb5/vl6anYn849dVnkNq1qvnW/kNkjl3XbOX+LHOtk65xq20Vu57Ln+5qqOpjkJUk+Onf1ZvfzqucbSW6qqpur6o1z6+yp85fktfn6B0urOn/b2Xa3zt/Cdi3AVfXPVXXXJl9bPUr82i42uW7j/yP3uvz/O/SBJN8+xnhJkl9J8pdVdX7DfO9I8p1Jvn+a6e0LbLPK+daPcW2SLyd5z3TVwufvdI91inUWPic7sJP5ZgurvjnJ3yS5Zozx2HT1ye7nVc/3g2OMS5NcleSXquqHtznHyezG+Xtqklcn+eu55as8f8vYdtft360djTGuONmyqnpw/end9DTlC5us9tkkL5j78/OTfG5uH/uT/EySl84d88kkT06Xb66qe5N8V5Jj2WCZ840xHpzb1x8n+YdFbtOq5pv28YYkP57kVWN6ket0zt/pHGuLdZ56im0XuZ2L2Ml8qapvyiy+7xlj/O36Cqe4n1c63xhj/fsXqur9mT2t/tfskfM3uSrJLfPnbMXnbzvb7tb5W9iqXoL4+yRvmC6/IcnfbbLOx5O8sKounv7r+dppu3VXJLlnjPHZ9Suq6tlVtW+6fEmSFya5b9XzbXjt66eT3DW339dW1TlVdfE038ca5rsyya8lefUY48T6Bjs4f1vdV+szv75mXpHk0elp3am2XeR2LmLb802/Z/iTJHePMX5/foNT3M+rnO/pVfWMaZ6nZ/YL1vmft9bzN7d847PVVZ+/7Wy7W+dvccv+Ld/0YOtbk3wwyaen7xdM1z8vyY1z612d2W+d701y7YZ9vCvJmzZc97NJPpHZbzJvSfITHfMl+fMkdya5I7M78blzy66d1v9kkqua5lvL7HWv26avd+70/G12rCRvWr+PMnuq90fT8juTXLbAnJvezm2es23Nl+SHMntKesfc+bp6q/t5hfNdMt1ft0/33Z46f9Oy85J8MckzN+xzlefv2zJ7tPtYkv+aLp+/qp+/Rb+8FRmgiXfCATQRYIAmAgzQRIABmggwQBMB5oxTVddU1XkLrHd/VV24iplgOwSYM9E1mf2/pnBGE2D2tOmdX/9YVbdPn43xm5m9AeVDVfWhaZ13VNWxmn1+729t2MWvVtXHpq9DK78BcAq79lkQsCRXJvncGOPHkqSqnpnk55O8cozx8LTOtWOMR6a3VX+wqr5vjHHHtOyxMcbLq+r1Sf4gs8/DgD3BI2D2ujuTXFFV11XV5WOMRzdZ5zVVdUuSW5N8T2YfhL/uvXPff2C5o8Lp8QiYPW2M8amqemlm79//naq6aX759CFHb07ysjHGf1bVu5I8bX4XJ7kM7TwCZk+rquclOTHG+Iskv5fk0iSPZ/bPBSXJ+Un+O8mjVXVRZh+DOO/n5r5/ePkTw+I8Amav+94kb6uqr2b2z8v8YmYvJXygqh4YY7yyqm7N7JPB7kvybxu2P6eqPprZg43XrXBu2JJPQwNo4iUIgCYCDNBEgAGaCDBAEwEGaCLAAE0EGKDJ/wFyyd116kU0mQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking Outliers\n",
    "sns.boxplot(df['stab'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Logistic Regression\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X=df.drop(['stabf'],axis=1)\n",
    "Y=df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8985"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "model=LogisticRegression(random_state=0,multi_class='ovr',solver='lbfgs')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9515"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "svm_model = svm.SVC(kernel='rbf',C=30,gamma='auto')\n",
    "svm_model.fit(X_train,y_train)\n",
    "svm_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(gamma='auto'),\n",
       "             param_grid={'C': [1, 10, 20], 'kernel': ['rbf', 'linear']})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(svm.SVC(gamma='auto'),{\n",
    "    'C': [1,10,20],\n",
    "    'kernel':['rbf','linear']\n",
    "},cv=5,return_train_score=False)\n",
    "\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.104053</td>\n",
       "      <td>0.127417</td>\n",
       "      <td>0.148404</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.9108</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.600343</td>\n",
       "      <td>0.164688</td>\n",
       "      <td>0.056424</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.007325</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.946860</td>\n",
       "      <td>0.078042</td>\n",
       "      <td>0.081786</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.676391</td>\n",
       "      <td>0.336028</td>\n",
       "      <td>0.033315</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>0.9885</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.9830</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.227643</td>\n",
       "      <td>0.077278</td>\n",
       "      <td>0.079027</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 20, 'kernel': 'rbf'}</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.065803</td>\n",
       "      <td>0.125918</td>\n",
       "      <td>0.027961</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       1.104053      0.127417         0.148404        0.013264       1   \n",
       "1       1.600343      0.164688         0.056424        0.001012       1   \n",
       "2       0.946860      0.078042         0.081786        0.000624      10   \n",
       "3       2.676391      0.336028         0.033315        0.003383      10   \n",
       "4       1.227643      0.077278         0.079027        0.005226      20   \n",
       "5       3.065803      0.125918         0.027961        0.001724      20   \n",
       "\n",
       "  param_kernel                         params  split0_test_score  \\\n",
       "0          rbf      {'C': 1, 'kernel': 'rbf'}             0.9070   \n",
       "1       linear   {'C': 1, 'kernel': 'linear'}             0.9520   \n",
       "2          rbf     {'C': 10, 'kernel': 'rbf'}             0.9520   \n",
       "3       linear  {'C': 10, 'kernel': 'linear'}             0.9890   \n",
       "4          rbf     {'C': 20, 'kernel': 'rbf'}             0.9470   \n",
       "5       linear  {'C': 20, 'kernel': 'linear'}             0.9925   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0             0.9075             0.9200             0.9160             0.9035   \n",
       "1             0.9510             0.9605             0.9425             0.9400   \n",
       "2             0.9500             0.9475             0.9525             0.9440   \n",
       "3             0.9885             0.9925             0.9845             0.9830   \n",
       "4             0.9535             0.9485             0.9515             0.9450   \n",
       "5             0.9915             0.9945             0.9870             0.9895   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.9108        0.006169                6  \n",
       "1           0.9492        0.007325                3  \n",
       "2           0.9492        0.003140                3  \n",
       "3           0.9875        0.003391                2  \n",
       "4           0.9491        0.003056                5  \n",
       "5           0.9910        0.002569                1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(clf.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.9108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.9492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.9492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.9491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.9910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0       1          rbf           0.9108\n",
       "1       1       linear           0.9492\n",
       "2      10          rbf           0.9492\n",
       "3      10       linear           0.9875\n",
       "4      20          rbf           0.9491\n",
       "5      20       linear           0.9910"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['param_C','param_kernel','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the best model with best parameters\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='lbfgs',multi_class='ovr'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Karthick\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>{'C': 20, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>{'C': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                    best_params\n",
       "0                  svm      0.9910  {'C': 20, 'kernel': 'linear'}\n",
       "1        random_forest      0.9997           {'n_estimators': 10}\n",
       "2  logistic_regression      0.9721                      {'C': 10}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X, Y)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
